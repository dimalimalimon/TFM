{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b5d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from xml.etree import ElementTree\n",
    "from utils import *\n",
    "from get_data_from_XML import *\n",
    "from getUID import *\n",
    "from get_gt import *\n",
    "from roi2rect import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c3f1ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series UID</th>\n",
       "      <th>Collection</th>\n",
       "      <th>3rd Party Analysis</th>\n",
       "      <th>Data Description URI</th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Study UID</th>\n",
       "      <th>Study Description</th>\n",
       "      <th>Study Date</th>\n",
       "      <th>Series Description</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Modality</th>\n",
       "      <th>SOP Class Name</th>\n",
       "      <th>SOP Class UID</th>\n",
       "      <th>Number of Images</th>\n",
       "      <th>File Size</th>\n",
       "      <th>File Location</th>\n",
       "      <th>Download Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.481038456248...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0001</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.269197582919...</td>\n",
       "      <td>Chest</td>\n",
       "      <td>03-11-2007</td>\n",
       "      <td>10mm</td>\n",
       "      <td>GE MEDICAL SYSTEMS</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.2</td>\n",
       "      <td>23</td>\n",
       "      <td>12.15 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0001/03-11-2007-NA-C...</td>\n",
       "      <td>2023-04-02T21:45:40.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.228104424729...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0002</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.171919653996...</td>\n",
       "      <td>Chest</td>\n",
       "      <td>09-05-2004</td>\n",
       "      <td>5mm</td>\n",
       "      <td>Philips</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.2</td>\n",
       "      <td>51</td>\n",
       "      <td>26.89 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0002/09-05-2004-NA-C...</td>\n",
       "      <td>2023-04-02T21:45:47.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.274175502344...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0002</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.171919653996...</td>\n",
       "      <td>Chest</td>\n",
       "      <td>09-05-2004</td>\n",
       "      <td>5mm</td>\n",
       "      <td>Philips</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.2</td>\n",
       "      <td>51</td>\n",
       "      <td>26.89 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0002/09-05-2004-NA-C...</td>\n",
       "      <td>2023-04-02T21:45:53.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.255626613690...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0003</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.992631987710...</td>\n",
       "      <td>CHESTC</td>\n",
       "      <td>07-27-2006</td>\n",
       "      <td>5mm</td>\n",
       "      <td>GE MEDICAL SYSTEMS</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.2</td>\n",
       "      <td>51</td>\n",
       "      <td>26.96 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0003/07-27-2006-NA-C...</td>\n",
       "      <td>2023-04-02T21:46:04.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.949618962952...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0003</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.992631987710...</td>\n",
       "      <td>CHESTC</td>\n",
       "      <td>07-27-2006</td>\n",
       "      <td>5mm</td>\n",
       "      <td>GE MEDICAL SYSTEMS</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.2</td>\n",
       "      <td>153</td>\n",
       "      <td>80.87 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0003/07-27-2006-NA-C...</td>\n",
       "      <td>2023-04-02T21:46:21.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.112642828995...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0042</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.145831440813...</td>\n",
       "      <td>PET03CBMWholebodyFirstHead Adult</td>\n",
       "      <td>10-15-2010</td>\n",
       "      <td>Range-CT WB  1.0  B30f-Tra-ALPHA Range</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>CT</td>\n",
       "      <td>Secondary Capture Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.7</td>\n",
       "      <td>169</td>\n",
       "      <td>133.33 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0042/10-15-2010-NA-P...</td>\n",
       "      <td>2023-04-03T00:10:11.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.133987507545...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0045</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.284757959801...</td>\n",
       "      <td>PET01PTheadlung Adult</td>\n",
       "      <td>05-08-2011</td>\n",
       "      <td>Thorax  1.0  B70f</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.2</td>\n",
       "      <td>376</td>\n",
       "      <td>198.43 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0045/05-08-2011-NA-P...</td>\n",
       "      <td>2023-04-03T00:10:52.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.239458321728...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0046</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.148329073455...</td>\n",
       "      <td>PET03CBMWholebodyFirstHead Adult</td>\n",
       "      <td>12-01-2010</td>\n",
       "      <td>Thorax  1.0  B70f</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.2</td>\n",
       "      <td>429</td>\n",
       "      <td>226.41 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0046/12-01-2010-NA-P...</td>\n",
       "      <td>2023-04-03T00:11:40.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.115355634033...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0034</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.309937123803...</td>\n",
       "      <td>PET03WholebodyFirstHead Adult</td>\n",
       "      <td>11-09-2009</td>\n",
       "      <td>Range-Thorax  1.0  B70f-Tra-ALPHA Range</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>CT</td>\n",
       "      <td>Secondary Capture Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.7</td>\n",
       "      <td>255</td>\n",
       "      <td>201.18 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0034/11-09-2009-NA-P...</td>\n",
       "      <td>2023-04-03T00:12:14.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.175448620220...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0051</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.127146483723...</td>\n",
       "      <td>PET03CBMWholebodyFirstHead Adult</td>\n",
       "      <td>11-04-2010</td>\n",
       "      <td>Thorax  1.0  B70f</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.2</td>\n",
       "      <td>411</td>\n",
       "      <td>216.91 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0051/11-04-2010-NA-P...</td>\n",
       "      <td>2023-04-03T00:13:38.806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Series UID      Collection  \\\n",
       "1032  1.3.6.1.4.1.14519.5.2.1.6655.2359.481038456248...  Lung-PET-CT-Dx   \n",
       "1033  1.3.6.1.4.1.14519.5.2.1.6655.2359.228104424729...  Lung-PET-CT-Dx   \n",
       "1034  1.3.6.1.4.1.14519.5.2.1.6655.2359.274175502344...  Lung-PET-CT-Dx   \n",
       "1035  1.3.6.1.4.1.14519.5.2.1.6655.2359.255626613690...  Lung-PET-CT-Dx   \n",
       "1037  1.3.6.1.4.1.14519.5.2.1.6655.2359.949618962952...  Lung-PET-CT-Dx   \n",
       "...                                                 ...             ...   \n",
       "1287  1.3.6.1.4.1.14519.5.2.1.6655.2359.112642828995...  Lung-PET-CT-Dx   \n",
       "1288  1.3.6.1.4.1.14519.5.2.1.6655.2359.133987507545...  Lung-PET-CT-Dx   \n",
       "1289  1.3.6.1.4.1.14519.5.2.1.6655.2359.239458321728...  Lung-PET-CT-Dx   \n",
       "1290  1.3.6.1.4.1.14519.5.2.1.6655.2359.115355634033...  Lung-PET-CT-Dx   \n",
       "1291  1.3.6.1.4.1.14519.5.2.1.6655.2359.175448620220...  Lung-PET-CT-Dx   \n",
       "\n",
       "     3rd Party Analysis                        Data Description URI  \\\n",
       "1032                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "1033                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "1034                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "1035                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "1037                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "...                 ...                                         ...   \n",
       "1287                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "1288                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "1289                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "1290                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "1291                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "\n",
       "         Subject ID                                          Study UID  \\\n",
       "1032  Lung_Dx-G0001  1.3.6.1.4.1.14519.5.2.1.6655.2359.269197582919...   \n",
       "1033  Lung_Dx-G0002  1.3.6.1.4.1.14519.5.2.1.6655.2359.171919653996...   \n",
       "1034  Lung_Dx-G0002  1.3.6.1.4.1.14519.5.2.1.6655.2359.171919653996...   \n",
       "1035  Lung_Dx-G0003  1.3.6.1.4.1.14519.5.2.1.6655.2359.992631987710...   \n",
       "1037  Lung_Dx-G0003  1.3.6.1.4.1.14519.5.2.1.6655.2359.992631987710...   \n",
       "...             ...                                                ...   \n",
       "1287  Lung_Dx-G0042  1.3.6.1.4.1.14519.5.2.1.6655.2359.145831440813...   \n",
       "1288  Lung_Dx-G0045  1.3.6.1.4.1.14519.5.2.1.6655.2359.284757959801...   \n",
       "1289  Lung_Dx-G0046  1.3.6.1.4.1.14519.5.2.1.6655.2359.148329073455...   \n",
       "1290  Lung_Dx-G0034  1.3.6.1.4.1.14519.5.2.1.6655.2359.309937123803...   \n",
       "1291  Lung_Dx-G0051  1.3.6.1.4.1.14519.5.2.1.6655.2359.127146483723...   \n",
       "\n",
       "                     Study Description  Study Date  \\\n",
       "1032                             Chest  03-11-2007   \n",
       "1033                             Chest  09-05-2004   \n",
       "1034                             Chest  09-05-2004   \n",
       "1035                            CHESTC  07-27-2006   \n",
       "1037                            CHESTC  07-27-2006   \n",
       "...                                ...         ...   \n",
       "1287  PET03CBMWholebodyFirstHead Adult  10-15-2010   \n",
       "1288             PET01PTheadlung Adult  05-08-2011   \n",
       "1289  PET03CBMWholebodyFirstHead Adult  12-01-2010   \n",
       "1290     PET03WholebodyFirstHead Adult  11-09-2009   \n",
       "1291  PET03CBMWholebodyFirstHead Adult  11-04-2010   \n",
       "\n",
       "                           Series Description        Manufacturer Modality  \\\n",
       "1032                                     10mm  GE MEDICAL SYSTEMS       CT   \n",
       "1033                                      5mm             Philips       CT   \n",
       "1034                                      5mm             Philips       CT   \n",
       "1035                                      5mm  GE MEDICAL SYSTEMS       CT   \n",
       "1037                                      5mm  GE MEDICAL SYSTEMS       CT   \n",
       "...                                       ...                 ...      ...   \n",
       "1287   Range-CT WB  1.0  B30f-Tra-ALPHA Range             SIEMENS       CT   \n",
       "1288                        Thorax  1.0  B70f             SIEMENS       CT   \n",
       "1289                        Thorax  1.0  B70f             SIEMENS       CT   \n",
       "1290  Range-Thorax  1.0  B70f-Tra-ALPHA Range             SIEMENS       CT   \n",
       "1291                        Thorax  1.0  B70f             SIEMENS       CT   \n",
       "\n",
       "                       SOP Class Name              SOP Class UID  \\\n",
       "1032                 CT Image Storage  1.2.840.10008.5.1.4.1.1.2   \n",
       "1033                 CT Image Storage  1.2.840.10008.5.1.4.1.1.2   \n",
       "1034                 CT Image Storage  1.2.840.10008.5.1.4.1.1.2   \n",
       "1035                 CT Image Storage  1.2.840.10008.5.1.4.1.1.2   \n",
       "1037                 CT Image Storage  1.2.840.10008.5.1.4.1.1.2   \n",
       "...                               ...                        ...   \n",
       "1287  Secondary Capture Image Storage  1.2.840.10008.5.1.4.1.1.7   \n",
       "1288                 CT Image Storage  1.2.840.10008.5.1.4.1.1.2   \n",
       "1289                 CT Image Storage  1.2.840.10008.5.1.4.1.1.2   \n",
       "1290  Secondary Capture Image Storage  1.2.840.10008.5.1.4.1.1.7   \n",
       "1291                 CT Image Storage  1.2.840.10008.5.1.4.1.1.2   \n",
       "\n",
       "      Number of Images  File Size  \\\n",
       "1032                23   12.15 MB   \n",
       "1033                51   26.89 MB   \n",
       "1034                51   26.89 MB   \n",
       "1035                51   26.96 MB   \n",
       "1037               153   80.87 MB   \n",
       "...                ...        ...   \n",
       "1287               169  133.33 MB   \n",
       "1288               376  198.43 MB   \n",
       "1289               429  226.41 MB   \n",
       "1290               255  201.18 MB   \n",
       "1291               411  216.91 MB   \n",
       "\n",
       "                                          File Location  \\\n",
       "1032  ./Lung-PET-CT-Dx/Lung_Dx-G0001/03-11-2007-NA-C...   \n",
       "1033  ./Lung-PET-CT-Dx/Lung_Dx-G0002/09-05-2004-NA-C...   \n",
       "1034  ./Lung-PET-CT-Dx/Lung_Dx-G0002/09-05-2004-NA-C...   \n",
       "1035  ./Lung-PET-CT-Dx/Lung_Dx-G0003/07-27-2006-NA-C...   \n",
       "1037  ./Lung-PET-CT-Dx/Lung_Dx-G0003/07-27-2006-NA-C...   \n",
       "...                                                 ...   \n",
       "1287  ./Lung-PET-CT-Dx/Lung_Dx-G0042/10-15-2010-NA-P...   \n",
       "1288  ./Lung-PET-CT-Dx/Lung_Dx-G0045/05-08-2011-NA-P...   \n",
       "1289  ./Lung-PET-CT-Dx/Lung_Dx-G0046/12-01-2010-NA-P...   \n",
       "1290  ./Lung-PET-CT-Dx/Lung_Dx-G0034/11-09-2009-NA-P...   \n",
       "1291  ./Lung-PET-CT-Dx/Lung_Dx-G0051/11-04-2010-NA-P...   \n",
       "\n",
       "           Download Timestamp  \n",
       "1032  2023-04-02T21:45:40.968  \n",
       "1033  2023-04-02T21:45:47.117  \n",
       "1034  2023-04-02T21:45:53.116  \n",
       "1035  2023-04-02T21:46:04.991  \n",
       "1037  2023-04-02T21:46:21.524  \n",
       "...                       ...  \n",
       "1287  2023-04-03T00:10:11.488  \n",
       "1288   2023-04-03T00:10:52.05  \n",
       "1289  2023-04-03T00:11:40.824  \n",
       "1290  2023-04-03T00:12:14.624  \n",
       "1291  2023-04-03T00:13:38.806  \n",
       "\n",
       "[192 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "metadata=pd.read_csv(\"../data/manifest-1608669183333/metadata.csv\")\n",
    "metadata=metadata[metadata[\"Subject ID\"].str.contains(\"G\")]\n",
    "metadata=metadata[metadata.Modality==\"CT\"]\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69107d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata[\"Number of Images\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846a70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_G=metadata[\"Subject ID\"]\n",
    "top_G=set([l[8:]for l in top_G])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e89324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series UID</th>\n",
       "      <th>Collection</th>\n",
       "      <th>3rd Party Analysis</th>\n",
       "      <th>Data Description URI</th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Study UID</th>\n",
       "      <th>Study Description</th>\n",
       "      <th>Study Date</th>\n",
       "      <th>Series Description</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Modality</th>\n",
       "      <th>SOP Class Name</th>\n",
       "      <th>SOP Class UID</th>\n",
       "      <th>Number of Images</th>\n",
       "      <th>File Size</th>\n",
       "      <th>File Location</th>\n",
       "      <th>Download Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.269178008582...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0031</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.375418541264...</td>\n",
       "      <td>lungc</td>\n",
       "      <td>10-22-2009</td>\n",
       "      <td>A phase 5mm Stnd SS50</td>\n",
       "      <td>GE MEDICAL SYSTEMS</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.2</td>\n",
       "      <td>180</td>\n",
       "      <td>95.16 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0031/10-22-2009-NA-l...</td>\n",
       "      <td>2023-04-02T21:57:21.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.265088720385...</td>\n",
       "      <td>Lung-PET-CT-Dx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.7937/TCIA.2020.NNC20461</td>\n",
       "      <td>Lung_Dx-G0031</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6655.2359.375418541264...</td>\n",
       "      <td>lungc</td>\n",
       "      <td>10-22-2009</td>\n",
       "      <td>5mm Lung SS50</td>\n",
       "      <td>GE MEDICAL SYSTEMS</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.2</td>\n",
       "      <td>60</td>\n",
       "      <td>31.72 MB</td>\n",
       "      <td>./Lung-PET-CT-Dx/Lung_Dx-G0031/10-22-2009-NA-l...</td>\n",
       "      <td>2023-04-02T21:59:18.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Series UID      Collection  \\\n",
       "1095  1.3.6.1.4.1.14519.5.2.1.6655.2359.269178008582...  Lung-PET-CT-Dx   \n",
       "1104  1.3.6.1.4.1.14519.5.2.1.6655.2359.265088720385...  Lung-PET-CT-Dx   \n",
       "\n",
       "     3rd Party Analysis                        Data Description URI  \\\n",
       "1095                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "1104                NaN  https://doi.org/10.7937/TCIA.2020.NNC20461   \n",
       "\n",
       "         Subject ID                                          Study UID  \\\n",
       "1095  Lung_Dx-G0031  1.3.6.1.4.1.14519.5.2.1.6655.2359.375418541264...   \n",
       "1104  Lung_Dx-G0031  1.3.6.1.4.1.14519.5.2.1.6655.2359.375418541264...   \n",
       "\n",
       "     Study Description  Study Date     Series Description        Manufacturer  \\\n",
       "1095             lungc  10-22-2009  A phase 5mm Stnd SS50  GE MEDICAL SYSTEMS   \n",
       "1104             lungc  10-22-2009          5mm Lung SS50  GE MEDICAL SYSTEMS   \n",
       "\n",
       "     Modality    SOP Class Name              SOP Class UID  Number of Images  \\\n",
       "1095       CT  CT Image Storage  1.2.840.10008.5.1.4.1.1.2               180   \n",
       "1104       CT  CT Image Storage  1.2.840.10008.5.1.4.1.1.2                60   \n",
       "\n",
       "     File Size                                      File Location  \\\n",
       "1095  95.16 MB  ./Lung-PET-CT-Dx/Lung_Dx-G0031/10-22-2009-NA-l...   \n",
       "1104  31.72 MB  ./Lung-PET-CT-Dx/Lung_Dx-G0031/10-22-2009-NA-l...   \n",
       "\n",
       "           Download Timestamp  \n",
       "1095  2023-04-02T21:57:21.274  \n",
       "1104  2023-04-02T21:59:18.934  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[metadata[\"Subject ID\"]==\"Lung_Dx-G0031\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59bce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49dcad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform rgb ctscan to grayscale using:(0.3 * R) + (0.59 * G) + (0.11 * B) \n",
    "def ct_to_gray(ctscan):\n",
    "    r = ctscan[:,:,0]\n",
    "    g = ctscan[:,:,1]\n",
    "    b = ctscan[:,:,2]\n",
    "    graybmp = np.multiply(0.3*r, 0.59*g)\n",
    "    graybmp = np.multiply(graybmp, 0.11*b)\n",
    "    return graybmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8b0b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9a407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6ee0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff7d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220d513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b918884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DICOMDataset(Dataset):\n",
    "    def __init__(self, matrix_list, y_list):\n",
    "        self.matrix_list = matrix_list\n",
    "        self.y_list = y_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.matrix_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        matrix = self.matrix_list[idx]\n",
    "        y = self.y_list[idx]\n",
    "        \n",
    "        return matrix, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732f5885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_565784/2662670305.py:43: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  pixel_array = dicom_image.pixel_array.astype(np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.469388796898719175810353557871.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.253499093725222144225669530250.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.136788945074661422691341468449.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.290562187116107174337012530942.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.264347398825533405596428888416.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.739386460021914982547403695156.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.119252578514908170756674082512.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.289795777072556464918247262981.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.218726992178117761342346852656.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.320042227231064887825199401077.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.224105378372985005294624637492.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.181645283216424958329412934571.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.969303944656256392202249384424.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.797618345174871002033433031749.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.474025779324365222879833550691.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.115035632118764464180844550456.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.321519079067291219913226581553.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.850427828491472021344142966656.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.451297787448672421148725075184.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.315374323288249590782612117962.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.105274714951287031677223560968.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.298347868086216040918047034750.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.197870234919324132749907296830.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.520135990421048040411054993796.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.490693798924639640128784981621.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.130070656958154988671820351290.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.630158987291111815993673084163.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.270753724029935511566570128099.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.128665131311867433297805143776.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.160595690406349148631674855504.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.141688024604531390737082208489.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.187504192464605447441682915181.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.225740301966755056994489928017.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.149683718884356862132706679037.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.239259910452367570932707074212.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.229621811492030808596148656662.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.224154467949229061688453733488.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.233893094591552562270449577716.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.227641314552337081856448368329.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.214659347447318156859324774526.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.322433059807319061135403867195.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.293877216888896261076554813579.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.167297401553676120741849246701.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.247473482551577607322210877971.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.298572817913257802010916872416.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.365618393959859948244706974319.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.101011955818542974300871993288.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.254184924592415445788703331251.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.143836262837039687173035649537.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.803183761210843759728754967870.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.267607371186173330652823550350.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.194242582627201188782352849475.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.332936206609150532870135441214.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.305612934725883662619292829293.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.158605576897598583511806756208.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.253711863416505944196442360785.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.284448185828837758479315791553.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.224635338336222185615023084818.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.624553693910347848146865266258.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.158702371932404095719594926270.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.183732131767901083971344685145.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.173527638645042380505887668692.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.275560974423236300011495209609.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.117517668952723642208470057105.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.214228282482026819663800780594.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.890787513864232205629142986475.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.125968625807283050794305281881.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.293830487504370064574314140267.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.247553647168482770211462799276.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.241854684551929460924240557394.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.251551694042170708500537948535.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.242886766499551239185884782663.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.138067560924855451499701843846.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.135982287945288897340010146605.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.893723977023058334905238309724.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.298315318903839891749480318975.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.127890571679208506708169753746.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.271999696291793870587655296361.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.271870224981790697094455546110.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.311019456183087556909766678792.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.993223392452531627018527513588.xml\n",
      "missing annotation file:  1.3.6.1.4.1.14519.5.2.1.6655.2359.111597331886493962511273045391.xml\n",
      "(3034,)\n",
      "(3034,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_565784/2662670305.py:70: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  x_all = np.array(x_all)\n",
      "/tmp/ipykernel_565784/2662670305.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_all = np.array(x_all)\n",
      "/tmp/ipykernel_565784/2662670305.py:71: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  y_all = np.array(y_all)\n",
      "/tmp/ipykernel_565784/2662670305.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_all = np.array(y_all)\n"
     ]
    }
   ],
   "source": [
    "###find files\n",
    "import pydicom\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "dicom_path = \"../data/manifest-1608669183333/Lung-PET-CT-Dx/\"\n",
    "annotation_path = \"../Lung-PET-CT-Dx-Annotations-XML-Files-rev12222020/Annotation/\"\n",
    "annon_files = os.listdir(annotation_path)\n",
    "ctlung_files = os.listdir(dicom_path)\n",
    "#variables to store data\n",
    "num_classes = 4\n",
    "x_all = []\n",
    "y_all = []\n",
    "\n",
    "#iterate over ct scans\n",
    "for subject_name in annon_files:\n",
    "    if \"B\" in subject_name: #use subset B only since it is small and we are running stuff locally\n",
    "        annon_path = annotation_path + subject_name\n",
    "        ctlung_path = dicom_path + \"Lung_Dx-\" + subject_name\n",
    "        \n",
    "        if not os.path.isdir(ctlung_path):\n",
    "            print(\"missing file: \", ctlung_path)\n",
    "            continue\n",
    "        #print(ctlung_path)\n",
    "        lungs = getUID_path(ctlung_path) #get dict with xml:ctscan_num \n",
    "        #print(lungs)\n",
    "        annotations = XML_preprocessor(annon_path, num_classes=num_classes).data\n",
    "        for k, v in annotations.items():\n",
    "        \n",
    "            key = k[:-4] #quitamos xml del nombre\n",
    "            if key not in lungs:\n",
    "                print(\"missing annotation file: \", k)\n",
    "                continue\n",
    "            image_data = v[0]\n",
    "            image_data=[int(i) for i in image_data]\n",
    "            \n",
    "            bounding_box = [image_data[0], image_data[1], image_data[2], image_data[3]]\n",
    "            #print(bounding_box)\n",
    "\n",
    "            dcm_path, dcm_name = lungs[k[:-4]]\n",
    "            dicom_image = pydicom.read_file(dcm_path)\n",
    "            #print(matrix,matrix.shape,ch)\n",
    "            pixel_array = dicom_image.pixel_array.astype(np.float)\n",
    "            if len(pixel_array.shape) == 3: #assume bitmap is rgb\n",
    "                pixel_array = ct_to_gray(pixel_array)\n",
    "                \n",
    "            pixel_array = pixel_array / np.max(pixel_array)\n",
    "            #print(pixel_array,pixel_array.shape)\n",
    "            #bw_image = np.zeros_like(pixel_array)\n",
    "            #threshold=0.5\n",
    "            #bw_image[pixel_array > threshold] = 1\n",
    "            #del pixel_array\n",
    "            #mask = np.zeros_like(pixel_array)\n",
    "            #mask[image_data[1]:image_data[3], image_data[0]:image_data[2]] = 1\n",
    "            #print(bw_image,bw_image.shape)\n",
    "            pixel_array = np.expand_dims(pixel_array, axis=-1)\n",
    "            #print(pixel_array.shape)\n",
    "            #print(dcm_path)\n",
    "            #plt.imshow(pixel_array, cmap='gray')\n",
    "            #plt.show()\n",
    "            #plt.imshow(mask, cmap='gray')\n",
    "            #plt.show()\n",
    "            #ctscan_map = ctscan_map.reshape(np.prod(ctscan_map.shape))/255\n",
    "            #break\n",
    "            x_all.append(torch.tensor(pixel_array))\n",
    "\n",
    "        #get xmin, ymin, xmax, ymax that define the square and will be predicted\n",
    "            y_all.append(torch.tensor(np.array([image_data[0], image_data[1], image_data[2], image_data[3]])))\n",
    "\n",
    "x_all = np.array(x_all)\n",
    "y_all = np.array(y_all)\n",
    "print(x_all.shape)\n",
    "print(y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe64b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fc9968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([823, 999, 891, 781, 967, 764, 954, 693,  26,  99, 811,   3, 658,\n",
       "       112,  42, 666, 809, 386, 531, 463, 102, 461, 321,  45,  55, 829,\n",
       "       976, 873, 146, 962, 879, 171, 282, 750, 271, 125, 252,  20, 888,\n",
       "       264, 634, 762, 582, 825, 530, 866, 814,   4, 157, 328, 794, 757,\n",
       "       356, 617, 305, 599, 594, 436, 294, 265, 218, 444, 766, 529, 151,\n",
       "       111, 852, 293, 148, 560, 842, 574, 936, 465, 476, 389,  34, 306,\n",
       "       670, 980, 876, 221, 889, 649, 136,  91, 692, 334, 899, 160, 652,\n",
       "       401, 181, 211, 205,  27, 875,  30, 260, 236])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "sampled_index = np.random.choice(np.array(list(range(len(x_all)))), size=100, replace=False)\n",
    "sampled_index              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94ba5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all=x_all[sampled_index]\n",
    "y_all=y_all[sampled_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4c0284a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(x_all.shape)\n",
    "print(y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59c0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = DICOMDataset(x_all, y_all)\n",
    "\n",
    "# Split dataset into train and test\n",
    "train_size = int(0.8 * len(custom_dataset))\n",
    "test_size = len(custom_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(custom_dataset, [train_size, test_size])\n",
    "\n",
    "# Create dataloaders for train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5ae86",
   "metadata": {},
   "source": [
    "# Trying Torch model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7cb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcacab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88a0b5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0266, 0.0188, 0.0564, 0.0394], grad_fn=<SelectBackward0>) tensor([115., 244., 173., 289.])\n",
      "tensor([0.0100, 0.0115, 0.0581, 0.0422], grad_fn=<SelectBackward0>) tensor([142., 277., 238., 357.])\n",
      "tensor([0.0274, 0.0231, 0.0510, 0.0400], grad_fn=<SelectBackward0>) tensor([186., 300., 233., 356.])\n",
      "tensor([0.0252, 0.0199, 0.0509, 0.0325], grad_fn=<SelectBackward0>) tensor([319., 260., 359., 300.])\n",
      "tensor([0.0293, 0.0217, 0.0475, 0.0396], grad_fn=<SelectBackward0>) tensor([295., 294., 388., 400.])\n",
      "tensor([0.0289, 0.0204, 0.0450, 0.0383], grad_fn=<SelectBackward0>) tensor([301., 300., 388., 403.])\n",
      "tensor([0.0122, 0.0174, 0.0515, 0.0429], grad_fn=<SelectBackward0>) tensor([152., 176., 219., 286.])\n",
      "tensor([0.0270, 0.0262, 0.0499, 0.0405], grad_fn=<SelectBackward0>) tensor([325., 271., 355., 325.])\n",
      "tensor([0.0208, 0.0246, 0.0546, 0.0395], grad_fn=<SelectBackward0>) tensor([169., 315., 226., 415.])\n",
      "tensor([0.0216, 0.0235, 0.0512, 0.0362], grad_fn=<SelectBackward0>) tensor([158., 310., 232., 401.])\n",
      "tensor([0.0225, 0.0218, 0.0520, 0.0411], grad_fn=<SelectBackward0>) tensor([317., 274., 360., 336.])\n",
      "tensor([0.0104, 0.0126, 0.0554, 0.0413], grad_fn=<SelectBackward0>) tensor([185., 305., 219., 354.])\n",
      "tensor([0.0239, 0.0214, 0.0514, 0.0415], grad_fn=<SelectBackward0>) tensor([314., 303., 398., 389.])\n",
      "tensor([0.0067, 0.0068, 0.0654, 0.0446], grad_fn=<SelectBackward0>) tensor([153., 288., 231., 385.])\n",
      "tensor([0.0241, 0.0190, 0.0519, 0.0395], grad_fn=<SelectBackward0>) tensor([218., 339., 241., 369.])\n",
      "tensor([0.0262, 0.0212, 0.0524, 0.0396], grad_fn=<SelectBackward0>) tensor([296., 296., 394., 400.])\n",
      "tensor([1.0864, 1.3887, 1.0615, 1.5297], grad_fn=<SelectBackward0>) tensor([288., 300., 355., 360.])\n",
      "tensor([1.6013, 2.0997, 1.5908, 2.3334], grad_fn=<SelectBackward0>) tensor([367., 280., 397., 316.])\n",
      "tensor([1.1002, 1.4049, 1.0773, 1.5486], grad_fn=<SelectBackward0>) tensor([337., 273., 376., 322.])\n",
      "tensor([1.0744, 1.3789, 1.0545, 1.5197], grad_fn=<SelectBackward0>) tensor([151., 228., 221., 317.])\n",
      "tensor([1.1248, 1.4392, 1.1032, 1.5864], grad_fn=<SelectBackward0>) tensor([318., 264., 379., 325.])\n",
      "tensor([1.2763, 1.6597, 1.2594, 1.8378], grad_fn=<SelectBackward0>) tensor([154., 181., 228., 290.])\n",
      "tensor([1.1365, 1.4549, 1.1084, 1.6033], grad_fn=<SelectBackward0>) tensor([195., 315., 238., 351.])\n",
      "tensor([1.3489, 1.7378, 1.3097, 1.9033], grad_fn=<SelectBackward0>) tensor([153., 309., 235., 407.])\n",
      "tensor([1.3558, 1.7658, 1.3349, 1.9661], grad_fn=<SelectBackward0>) tensor([153., 280., 241., 383.])\n",
      "tensor([1.4762, 1.9248, 1.4609, 2.1464], grad_fn=<SelectBackward0>) tensor([141., 274., 199., 324.])\n",
      "tensor([1.3500, 1.7601, 1.3330, 1.9558], grad_fn=<SelectBackward0>) tensor([167., 289., 227., 368.])\n",
      "tensor([1.3277, 1.7024, 1.2891, 1.8651], grad_fn=<SelectBackward0>) tensor([309., 276., 357., 325.])\n",
      "tensor([1.4522, 1.8973, 1.4355, 2.1078], grad_fn=<SelectBackward0>) tensor([275., 226., 378., 348.])\n",
      "tensor([1.1119, 1.4247, 1.0864, 1.5666], grad_fn=<SelectBackward0>) tensor([325., 287., 371., 338.])\n",
      "tensor([1.3441, 1.7510, 1.3276, 1.9483], grad_fn=<SelectBackward0>) tensor([146., 259., 245., 395.])\n",
      "tensor([1.2494, 1.6104, 1.2190, 1.7673], grad_fn=<SelectBackward0>) tensor([328., 266., 384., 359.])\n",
      "tensor([32.0952, 39.5152, 39.0339, 46.4507], grad_fn=<SelectBackward0>) tensor([169., 284., 251., 363.])\n",
      "tensor([31.2025, 38.3896, 37.9212, 45.1207], grad_fn=<SelectBackward0>) tensor([148., 284., 184., 321.])\n",
      "tensor([32.9038, 40.4995, 40.0452, 47.6257], grad_fn=<SelectBackward0>) tensor([133., 292., 181., 347.])\n",
      "tensor([33.1284, 40.6242, 40.1420, 47.6653], grad_fn=<SelectBackward0>) tensor([315., 257., 350., 291.])\n",
      "tensor([33.4693, 41.0504, 40.5653, 48.1531], grad_fn=<SelectBackward0>) tensor([316., 295., 364., 341.])\n",
      "tensor([34.3752, 42.1581, 41.6588, 49.4696], grad_fn=<SelectBackward0>) tensor([315., 243., 393., 316.])\n",
      "tensor([31.5564, 38.6866, 38.2095, 45.4185], grad_fn=<SelectBackward0>) tensor([294., 293., 399., 396.])\n",
      "tensor([28.2125, 34.6029, 34.2029, 40.6178], grad_fn=<SelectBackward0>) tensor([310., 257., 388., 318.])\n",
      "tensor([32.7786, 40.2343, 39.7393, 47.2206], grad_fn=<SelectBackward0>) tensor([293., 315., 334., 371.])\n",
      "tensor([33.5437, 41.1406, 40.6486, 48.2655], grad_fn=<SelectBackward0>) tensor([324., 317., 348., 343.])\n",
      "tensor([31.2269, 38.4031, 37.9500, 45.1334], grad_fn=<SelectBackward0>) tensor([ 81., 309., 195., 387.])\n",
      "tensor([29.4656, 36.1297, 35.7171, 42.3898], grad_fn=<SelectBackward0>) tensor([318., 260., 360., 300.])\n",
      "tensor([32.6087, 40.1341, 39.6626, 47.1997], grad_fn=<SelectBackward0>) tensor([301., 336., 342., 372.])\n",
      "tensor([31.8824, 39.2473, 38.7571, 46.1325], grad_fn=<SelectBackward0>) tensor([164., 295., 232., 367.])\n",
      "tensor([31.9158, 39.2635, 38.7961, 46.1453], grad_fn=<SelectBackward0>) tensor([187., 142., 278., 315.])\n",
      "tensor([33.4390, 41.0289, 40.5344, 48.1440], grad_fn=<SelectBackward0>) tensor([313., 274., 355., 322.])\n",
      "tensor([33552.8047, 37555.3906, 41928.1523, 46282.5547],\n",
      "       grad_fn=<SelectBackward0>) tensor([313., 198., 365., 270.])\n",
      "tensor([36693.3594, 41050.9102, 45846.1289, 50588.7852],\n",
      "       grad_fn=<SelectBackward0>) tensor([334., 252., 389., 312.])\n",
      "tensor([31163.0840, 34863.5000, 38936.4219, 42963.3906],\n",
      "       grad_fn=<SelectBackward0>) tensor([319., 247., 349., 278.])\n",
      "tensor([29776.1582, 33311.1250, 37203.0664, 41050.5430],\n",
      "       grad_fn=<SelectBackward0>) tensor([313., 266., 366., 343.])\n",
      "tensor([33994.5742, 38050.5586, 42480.2148, 46893.6289],\n",
      "       grad_fn=<SelectBackward0>) tensor([140., 277., 198., 326.])\n",
      "tensor([30894.2656, 34562.2852, 38600.3320, 42592.2891],\n",
      "       grad_fn=<SelectBackward0>) tensor([311., 293., 369., 339.])\n",
      "tensor([31570.2812, 35336.4727, 39450.5039, 43548.1406],\n",
      "       grad_fn=<SelectBackward0>) tensor([ 76., 254., 236., 400.])\n",
      "tensor([29628.0371, 33145.4258, 37018.0469, 40846.3906],\n",
      "       grad_fn=<SelectBackward0>) tensor([315., 302., 404., 388.])\n",
      "tensor([31115.5117, 34828.5977, 38882.9766, 42921.8164],\n",
      "       grad_fn=<SelectBackward0>) tensor([163., 321., 223., 392.])\n",
      "tensor([32816.7812, 36712.7695, 41001.3438, 45242.5547],\n",
      "       grad_fn=<SelectBackward0>) tensor([275., 287., 362., 364.])\n",
      "tensor([35910.1719, 40177.2969, 44868.7109, 49512.0312],\n",
      "       grad_fn=<SelectBackward0>) tensor([322., 208., 375., 300.])\n",
      "tensor([36709.7695, 41074.5977, 45867.8789, 50617.0898],\n",
      "       grad_fn=<SelectBackward0>) tensor([155., 303., 236., 394.])\n",
      "tensor([32725.5156, 36630.5781, 40894.5625, 45143.1875],\n",
      "       grad_fn=<SelectBackward0>) tensor([296., 329., 349., 376.])\n",
      "tensor([29821.7227, 33363.0195, 37260.1094, 41114.1914],\n",
      "       grad_fn=<SelectBackward0>) tensor([184., 307., 229., 373.])\n",
      "tensor([38630.8438, 43218.7461, 48266.9102, 53260.3984],\n",
      "       grad_fn=<SelectBackward0>) tensor([315., 238., 394., 324.])\n",
      "tensor([30410.1582, 34034.1641, 37999.6875, 41942.8281],\n",
      "       grad_fn=<SelectBackward0>) tensor([155., 242., 216., 318.])\n",
      "tensor([-4863.1401, -5443.4268, -6075.6938, -6706.7964],\n",
      "       grad_fn=<SelectBackward0>) tensor([298., 279., 343., 321.])\n",
      "tensor([ -9453.3135, -10581.8711, -11809.8291, -13036.2871],\n",
      "       grad_fn=<SelectBackward0>) tensor([325., 265., 355., 287.])\n",
      "tensor([-3594.7395, -4023.5583, -4490.9307, -4957.6807],\n",
      "       grad_fn=<SelectBackward0>) tensor([311., 266., 354., 337.])\n",
      "tensor([-4895.8169, -5480.4692, -6116.8672, -6752.3232],\n",
      "       grad_fn=<SelectBackward0>) tensor([174., 316., 222., 399.])\n",
      "tensor([ -7312.5474,  -8185.0942,  -9135.7773, -10084.6611],\n",
      "       grad_fn=<SelectBackward0>) tensor([310., 289., 347., 329.])\n",
      "tensor([-2.4745, -7.4551, -3.6106, -8.0967], grad_fn=<SelectBackward0>) tensor([ 81., 263., 222., 396.])\n",
      "tensor([-1.5397, -1.7782, -1.8651, -2.1471], grad_fn=<SelectBackward0>) tensor([328., 302., 373., 339.])\n",
      "tensor([ -7400.7236,  -8283.8633,  -9246.1182, -10206.1006],\n",
      "       grad_fn=<SelectBackward0>) tensor([315., 250., 348., 292.])\n",
      "tensor([ -2.9063,  -9.5224,  -4.2194, -10.4405], grad_fn=<SelectBackward0>) tensor([340., 262., 412., 346.])\n",
      "tensor([-2.5321, -6.8628, -3.2454, -6.5410], grad_fn=<SelectBackward0>) tensor([ 78., 249., 231., 395.])\n",
      "tensor([-5135.1484, -5748.5083, -6416.0303, -7082.4312],\n",
      "       grad_fn=<SelectBackward0>) tensor([179., 320., 219., 395.])\n",
      "tensor([-5265.0259, -5893.6787, -6577.9336, -7261.2646],\n",
      "       grad_fn=<SelectBackward0>) tensor([308., 246., 387., 320.])\n",
      "tensor([ -9.0478, -10.1352, -11.2579, -12.5252], grad_fn=<SelectBackward0>) tensor([323., 252., 387., 328.])\n",
      "tensor([-10569.0938, -11830.0273, -13204.1611, -14575.3408],\n",
      "       grad_fn=<SelectBackward0>) tensor([313., 265., 364., 339.])\n",
      "tensor([-6429.8281, -7197.1846, -8033.3511, -8867.2480],\n",
      "       grad_fn=<SelectBackward0>) tensor([301., 246., 412., 331.])\n",
      "tensor([-2.9702, -3.4277, -3.7319, -4.1775], grad_fn=<SelectBackward0>) tensor([344., 271., 370., 317.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 314615004.864\n",
      "tensor([2.2137e+08, 2.2699e+08, 2.7023e+08, 2.9459e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([154., 181., 228., 290.])\n",
      "tensor([1.7864e+08, 1.7969e+08, 2.1288e+08, 2.3109e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([133., 292., 181., 347.])\n",
      "tensor([1.8865e+08, 1.9205e+08, 2.2591e+08, 2.4658e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([296., 329., 349., 376.])\n",
      "tensor([2.8516e+08, 2.9823e+08, 3.5234e+08, 3.8821e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([317., 274., 360., 336.])\n",
      "tensor([1.6530e+08, 1.6575e+08, 1.9429e+08, 2.1131e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([340., 262., 412., 346.])\n",
      "tensor([2.9204e+08, 3.0231e+08, 3.5935e+08, 3.9368e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([308., 246., 387., 320.])\n",
      "tensor([2.8411e+08, 2.9599e+08, 3.5052e+08, 3.8544e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([186., 300., 233., 356.])\n",
      "tensor([2.9297e+08, 3.0407e+08, 3.6088e+08, 3.9605e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([334., 252., 389., 312.])\n",
      "tensor([2.8229e+08, 2.9537e+08, 3.4883e+08, 3.8449e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([315., 302., 404., 388.])\n",
      "tensor([2.8381e+08, 2.9650e+08, 3.5053e+08, 3.8597e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([328., 302., 373., 339.])\n",
      "tensor([2.9603e+08, 3.0705e+08, 3.6480e+08, 4.0006e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([315., 250., 348., 292.])\n",
      "tensor([2.9517e+08, 3.0646e+08, 3.6390e+08, 3.9911e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([169., 315., 226., 415.])\n",
      "tensor([2.8386e+08, 2.9643e+08, 3.5052e+08, 3.8587e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([318., 264., 379., 325.])\n",
      "tensor([1.8029e+08, 1.8173e+08, 2.1462e+08, 2.3316e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([ 78., 249., 231., 395.])\n",
      "tensor([2.8927e+08, 3.0253e+08, 3.5746e+08, 3.9389e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([319., 260., 359., 300.])\n",
      "tensor([2.8478e+08, 2.9789e+08, 3.5201e+08, 3.8788e+08],\n",
      "       grad_fn=<SelectBackward0>) tensor([184., 307., 229., 373.])\n",
      "tensor([-4.9123e+18, -5.0951e+18, -6.0317e+18, -6.6212e+18],\n",
      "       grad_fn=<SelectBackward0>) tensor([296., 296., 394., 400.])\n",
      "tensor([-3.4653e+18, -3.5934e+18, -4.2537e+18, -4.6691e+18],\n",
      "       grad_fn=<SelectBackward0>) tensor([ 81., 309., 195., 387.])\n",
      "tensor([-5.2570e+18, -5.4409e+18, -6.4389e+18, -7.0633e+18],\n",
      "       grad_fn=<SelectBackward0>) tensor([155., 303., 236., 394.])\n",
      "tensor([-7.5266e+18, -7.8002e+18, -9.2328e+18, -1.0133e+19],\n",
      "       grad_fn=<SelectBackward0>) tensor([115., 244., 173., 289.])\n",
      "tensor([-8.5960e+18, -8.9058e+18, -1.0541e+19, -1.1567e+19],\n",
      "       grad_fn=<SelectBackward0>) tensor([174., 316., 222., 399.])\n",
      "tensor([-1.1025e+18, -1.1440e+18, -1.3544e+18, -1.4869e+18],\n",
      "       grad_fn=<SelectBackward0>) tensor([323., 252., 387., 328.])\n",
      "tensor([-8.0279e+18, -8.3260e+18, -9.8566e+18, -1.0820e+19],\n",
      "       grad_fn=<SelectBackward0>) tensor([146., 259., 245., 395.])\n",
      "tensor([-3.1790e+18, -3.2901e+18, -3.8936e+18, -4.2711e+18],\n",
      "       grad_fn=<SelectBackward0>) tensor([311., 266., 354., 337.])\n",
      "tensor([-1.6387e+19, -1.7000e+19, -2.0126e+19, -2.2095e+19],\n",
      "       grad_fn=<SelectBackward0>) tensor([315., 243., 393., 316.])\n",
      "tensor([-1.2428e+19, -1.2891e+19, -1.5261e+19, -1.6754e+19],\n",
      "       grad_fn=<SelectBackward0>) tensor([325., 271., 355., 325.])\n",
      "tensor([-6.6655e+18, -6.9148e+18, -8.1860e+18, -8.9867e+18],\n",
      "       grad_fn=<SelectBackward0>) tensor([164., 295., 232., 367.])\n",
      "tensor([-8.5402e+18, -8.8564e+18, -1.0484e+19, -1.1508e+19],\n",
      "       grad_fn=<SelectBackward0>) tensor([167., 289., 227., 368.])\n",
      "tensor([-5.7363e+18, -5.9520e+18, -7.0464e+18, -7.7361e+18],\n",
      "       grad_fn=<SelectBackward0>) tensor([195., 315., 238., 351.])\n",
      "tensor([-1.0346e+18, -1.0733e+18, -1.2707e+18, -1.3949e+18],\n",
      "       grad_fn=<SelectBackward0>) tensor([344., 271., 370., 317.])\n",
      "tensor([-3.8152e+18, -3.9526e+18, -4.6790e+18, -5.1342e+18],\n",
      "       grad_fn=<SelectBackward0>) tensor([152., 176., 219., 286.])\n",
      "tensor([-7.8289e+18, -8.1169e+18, -9.6084e+18, -1.0546e+19],\n",
      "       grad_fn=<SelectBackward0>) tensor([295., 294., 388., 400.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([218., 339., 241., 369.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([163., 321., 223., 392.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([322., 208., 375., 300.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([153., 280., 241., 383.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([309., 276., 357., 325.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([313., 198., 365., 270.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([315., 238., 394., 324.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([142., 277., 238., 357.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([367., 280., 397., 316.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([310., 257., 388., 318.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([311., 293., 369., 339.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([ 76., 254., 236., 400.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([315., 257., 350., 291.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([319., 247., 349., 278.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([294., 293., 399., 396.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([179., 320., 219., 395.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([324., 317., 348., 343.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([158., 310., 232., 401.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([148., 284., 184., 321.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([318., 260., 360., 300.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([ 81., 263., 222., 396.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([151., 228., 221., 317.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([314., 303., 398., 389.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([153., 309., 235., 407.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([298., 279., 343., 321.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([275., 226., 378., 348.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([187., 142., 278., 315.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([169., 284., 251., 363.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([153., 288., 231., 385.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([293., 315., 334., 371.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([325., 265., 355., 287.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([310., 289., 347., 329.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([301., 246., 412., 331.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([316., 295., 364., 341.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([313., 266., 366., 343.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([325., 287., 371., 338.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([288., 300., 355., 360.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([301., 336., 342., 372.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([141., 274., 199., 324.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([155., 242., 216., 318.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([185., 305., 219., 354.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([328., 266., 384., 359.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([313., 265., 364., 339.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([140., 277., 198., 326.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([301., 300., 388., 403.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([313., 274., 355., 322.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([337., 273., 376., 322.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([275., 287., 362., 364.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss: nan\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([344., 271., 370., 317.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([296., 329., 349., 376.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([340., 262., 412., 346.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([301., 246., 412., 331.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([301., 300., 388., 403.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([301., 336., 342., 372.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([275., 226., 378., 348.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([185., 305., 219., 354.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([140., 277., 198., 326.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([315., 250., 348., 292.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([155., 303., 236., 394.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([323., 252., 387., 328.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([315., 257., 350., 291.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([319., 247., 349., 278.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([151., 228., 221., 317.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([169., 284., 251., 363.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([325., 265., 355., 287.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([179., 320., 219., 395.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([148., 284., 184., 321.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([167., 289., 227., 368.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([133., 292., 181., 347.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([322., 208., 375., 300.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([142., 277., 238., 357.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([309., 276., 357., 325.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([187., 142., 278., 315.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([315., 302., 404., 388.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([295., 294., 388., 400.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([313., 265., 364., 339.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([311., 266., 354., 337.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([195., 315., 238., 351.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([294., 293., 399., 396.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([153., 309., 235., 407.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([141., 274., 199., 324.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([311., 293., 369., 339.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([163., 321., 223., 392.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([313., 198., 365., 270.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([152., 176., 219., 286.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([334., 252., 389., 312.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([186., 300., 233., 356.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([337., 273., 376., 322.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([308., 246., 387., 320.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([325., 287., 371., 338.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([184., 307., 229., 373.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([174., 316., 222., 399.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([313., 274., 355., 322.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([155., 242., 216., 318.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([318., 264., 379., 325.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([328., 266., 384., 359.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([367., 280., 397., 316.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([324., 317., 348., 343.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([310., 289., 347., 329.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([ 81., 309., 195., 387.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([328., 302., 373., 339.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([169., 315., 226., 415.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([154., 181., 228., 290.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([153., 280., 241., 383.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([ 78., 249., 231., 395.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([288., 300., 355., 360.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([315., 243., 393., 316.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([ 76., 254., 236., 400.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([318., 260., 360., 300.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([115., 244., 173., 289.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([164., 295., 232., 367.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([313., 266., 366., 343.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([293., 315., 334., 371.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([275., 287., 362., 364.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([146., 259., 245., 395.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([158., 310., 232., 401.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([153., 288., 231., 385.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([314., 303., 398., 389.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([310., 257., 388., 318.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([296., 296., 394., 400.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([315., 238., 394., 324.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([218., 339., 241., 369.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([319., 260., 359., 300.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([298., 279., 343., 321.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([ 81., 263., 222., 396.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([317., 274., 360., 336.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([325., 271., 355., 325.])\n",
      "tensor([nan, nan, nan, nan], grad_fn=<SelectBackward0>) tensor([316., 295., 364., 341.])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(outputs)):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(outputs[i],labels[i])\n\u001b[0;32m---> 43\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     45\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define model architecture\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 128 * 128, 256)\n",
    "        self.fc2 = nn.Linear(256, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 128 * 128)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define model, loss function, and optimizer\n",
    "model = MyModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        #print(torch.permute(inputs,(0,3,1,2)).size())\n",
    "        inputs=torch.permute(inputs,(0,3,1,2))\n",
    "        inputs=inputs.float()\n",
    "        outputs = model(inputs)\n",
    "        labels=labels.float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        for i in range(len(outputs)):\n",
    "            print(outputs[i],labels[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d, loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))\n",
    "\n",
    "# Evaluate model on test set\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        # Visualize attention map\n",
    "        attention_map = model.attention_map(inputs)\n",
    "        print(attention_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf662e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf17ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df8731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ee025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb684191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e77702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ad7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed1497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990cae14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd7622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6e04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297f225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0268a083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051332cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b721a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192b139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367291e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370522d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###find files\n",
    "import pydicom\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "dicom_path = \"../data/manifest-1608669183333/Lung-PET-CT-Dx/\"\n",
    "annotation_path = \"../Lung-PET-CT-Dx-Annotations-XML-Files-rev12222020/Annotation/\"\n",
    "annon_files = os.listdir(annotation_path)\n",
    "ctlung_files = os.listdir(dicom_path)\n",
    "#variables to store data\n",
    "num_classes = 4\n",
    "x_all = []\n",
    "y_all = []\n",
    "\n",
    "#iterate over ct scans\n",
    "for subject_name in annon_files:\n",
    "    if \"B\" in subject_name: #use subset B only since it is small and we are running stuff locally\n",
    "        annon_path = annotation_path + subject_name\n",
    "        ctlung_path = dicom_path + \"Lung_Dx-\" + subject_name\n",
    "        \n",
    "        if not os.path.isdir(ctlung_path):\n",
    "            print(\"missing file: \", ctlung_path)\n",
    "            continue\n",
    "        #print(ctlung_path)\n",
    "        lungs = getUID_path(ctlung_path) #get dict with xml:ctscan_num \n",
    "        #print(lungs)\n",
    "        annotations = XML_preprocessor(annon_path, num_classes=num_classes).data\n",
    "        for k, v in annotations.items():\n",
    "        \n",
    "            key = k[:-4] #quitamos xml del nombre\n",
    "            if key not in lungs:\n",
    "                print(\"missing annotation file: \", k)\n",
    "                continue\n",
    "            image_data = v[0]\n",
    "            image_data=[int(i) for i in image_data]\n",
    "            \n",
    "            bounding_box = [image_data[0], image_data[1], image_data[2], image_data[3]]\n",
    "            print(bounding_box)\n",
    "\n",
    "            dcm_path, dcm_name = lungs[k[:-4]]\n",
    "            dicom_image = pydicom.read_file(dcm_path)\n",
    "            #print(matrix,matrix.shape,ch)\n",
    "            pixel_array = dicom_image.pixel_array.astype(np.float)\n",
    "            if len(pixel_array.shape) == 3: #assume bitmap is rgb\n",
    "                pixel_array = ct_to_gray(pixel_array)\n",
    "                \n",
    "            pixel_array = pixel_array / np.max(pixel_array)\n",
    "            #print(pixel_array,pixel_array.shape)\n",
    "            #bw_image = np.zeros_like(pixel_array)\n",
    "            #threshold=0.5\n",
    "            #bw_image[pixel_array > threshold] = 1\n",
    "            #del pixel_array\n",
    "            mask = np.zeros_like(pixel_array)\n",
    "            mask[image_data[1]:image_data[3], image_data[0]:image_data[2]] = 1\n",
    "            #print(bw_image,bw_image.shape)\n",
    "            pixel_array = np.expand_dims(pixel_array, axis=-1)\n",
    "            print(pixel_array.shape)\n",
    "            print(dcm_path)\n",
    "            plt.imshow(pixel_array, cmap='gray')\n",
    "            plt.show()\n",
    "            plt.imshow(mask, cmap='gray')\n",
    "            plt.show()\n",
    "            #ctscan_map = ctscan_map.reshape(np.prod(ctscan_map.shape))/255\n",
    "            break\n",
    "            x_all.append(ctscan_map)\n",
    "\n",
    "        #get xmin, ymin, xmax, ymax that define the square and will be predicted\n",
    "            y_all.append(np.array([v[0][0], v[0][1], v[0][2], v[0][3]]))\n",
    "\n",
    "x_all = np.array(x_all)\n",
    "y_all = np.array(y_all)\n",
    "print(x_all.shape)\n",
    "print(y_all.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
